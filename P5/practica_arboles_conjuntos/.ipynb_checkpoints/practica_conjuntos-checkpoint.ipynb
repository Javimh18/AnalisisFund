{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"height:40px\"><h2 style=\"align-content:center;padding:10px;color:white;background-color:#A4644E;float:left;margin-top:0px\">Experto en Big Data y Data Science</h2>\n",
    "<h2  style=\"align-content:center;padding:10px;color:white;background-color:#E0A030;float:left;margin-top:0px;\">Análisis de datos y su interpretación</h2></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conjuntos de clasificadores\n",
    "En esta práctica vamos a ver el funcionamiento básico de los conjuntos de clasificadores. Haremos algunos ejemplos en problemas en 2D para su visualización y con problemas reales para ver sus capacidades y debilidades. Al final de esta práctica serás capaz de:\n",
    "<ul>\n",
    "<li>Describir el proceso de combinación de clasificadores base en conjuntos y cómo se modifican las fronteras de decisión </li>\n",
    "<li>Medir tiempos de entrenamiento y de clasificación en  conjuntos de clasificadores y ver cómo varía con respecto a la creación de un único árbol</li>\n",
    "<li>Obtener el error de generalización de conjuntos de clasificadores en conjuntos de datos reales</li>\n",
    "<li>Analizar la importancia de las variables de entrenamiento en el modelo.</li>\n",
    "</ul>\n",
    "<p>Todas las cuestiones se contestarán en este notebook directamente, que es lo que deberéis entregar.\n",
    "Las cuestiones a responder están marcadas con fondo verde y vuestras respuestas deben ir en los cuadros en amarillo.</p> \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos los imports necesarios\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy.matlib as matl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.- Conjuntos de datos en 2D para el anáilisis visual de las fronteras de decisión y cómo cambian con algunos parámetros\n",
    "\n",
    "##### Funciones auxiliares\n",
    "Antes definiremos algunas funciones (autores Luis Lago y Manuel Sanchez Montañes) que usaremos a lo largo de la práctica. La primera, *createDataSet*, es para crear los problemas, siempre con dos clases y en dos dimensiones. Sus argumentos son:\n",
    "\n",
    "- *n*, número de patrones en el problema\n",
    "\n",
    "- *model*, tipo de modelo para la frontera que separa las clases, puede ser 'linear', 'square' o 'sine'\n",
    "\n",
    "- *ymargin*, margen de separación entre las dos clases, cuanto mayor es *ymargin* más separadas están las clases, valores negativos implican solape entre las clases\n",
    "\n",
    "- *noise*, introduce un ruido gausiano a la x e y\n",
    "\n",
    "- *output_boundary*, Si vale True la función devuelve la frontera de decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDataSet(n,model,ymargin,noise=None,output_boundary=False):\n",
    "    x = np.random.rand(n,1)*2.0*np.pi\n",
    "    xbnd = np.linspace(0,2.0*np.pi,100)\n",
    "\n",
    "    if model == 'sine':\n",
    "        y = (np.random.rand(n,1) - 0.5)*2.2\n",
    "        c = y > np.sin(x)\n",
    "        ybnd = np.sin(xbnd)\n",
    "    elif model == 'linear':\n",
    "        y = np.random.rand(n,1)*2.0*np.pi\n",
    "        c = y > x\n",
    "        ybnd = xbnd\n",
    "    elif model == 'square':\n",
    "        y = np.random.rand(n,1)*4.0*np.pi*np.pi\n",
    "        c = y > x*x\n",
    "        ybnd = xbnd*xbnd\n",
    "    else:\n",
    "        y = np.random.rand(n,1)*2.0*np.pi\n",
    "        c = y > x\n",
    "        ybnd = xbnd\n",
    "    \n",
    "    y[c == True] = y[c == True] + ymargin\n",
    "    y[c == False] = y[c == False] - ymargin\n",
    "    \n",
    "    if noise is not None:\n",
    "        y = y + noise * np.random.randn(n,1)\n",
    "        x = x + noise * np.random.randn(n,1)\n",
    "\n",
    "    if output_boundary == True:\n",
    "        return np.matlib.matrix(x), np.matlib.matrix(y), np.matlib.matrix(c*1), xbnd, ybnd\n",
    "    else:\n",
    "        return np.matlib.matrix(x), np.matlib.matrix(y), np.matlib.matrix(c*1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función *plotModel* la usaremos para dibujar el resultado de un clasificador sobre el conjunto de datos. Sus argumentos son:\n",
    "\n",
    "- *x*, coordenada x de los puntos\n",
    "\n",
    "- *y*, coordenada y de los puntos\n",
    "\n",
    "- *c*, clase de los puntos, si se pasa None, entonces considera que x e y son la frontera real de decisión y la muestra con plot\n",
    "\n",
    "- *clf*, el clasificador\n",
    "\n",
    "- *title*, título para el gráfico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotModel(x,y,clase,clf,title):\n",
    "    x_min, x_max = x.min() - .2, x.max() + .2\n",
    "    y_min, y_max = y.min() - .2, y.max() + .2\n",
    "    hx = (x_max - x_min)/100.\n",
    "    hy = (y_max - y_min)/100.\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, hx), np.arange(y_min, y_max, hy))\n",
    "\n",
    "    if hasattr(clf, \"decision_function\"):\n",
    "        z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
    "    else:\n",
    "        z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n",
    "\n",
    "    z = z.reshape(xx.shape)\n",
    "    cm = plt.cm.RdBu\n",
    "    cm_bright = ListedColormap(['#FF0000', '#0000FF'])\n",
    "    #ax = plt.subplot(1, 1, 1)\n",
    "    plt.contourf(xx, yy, z, cmap=cm, alpha=.8)\n",
    "    plt.contour(xx, yy, z, [0.5], linewidths=[2], colors=['k'])\n",
    "\n",
    "    if clase is not None:\n",
    "        plt.scatter([x[clase==0]], [y[clase==0]], c='#FF0000')\n",
    "        plt.scatter([x[clase==1]], [y[clase==1]], c='#0000FF')\n",
    "    else:\n",
    "        plt.plot(x,y,'g', linewidth=3)\n",
    "        \n",
    "    plt.gca().set_xlim(xx.min(), xx.max())\n",
    "    plt.gca().set_ylim(yy.min(), yy.max())\n",
    "    plt.grid(True)\n",
    "    plt.xlabel(\"X\")\n",
    "    plt.ylabel(\"Y\")\n",
    "    plt.title(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función, *plotData*, la usaremos para dibujar los datos. Sus argumentos son:\n",
    "\n",
    "- *x*, coordenada x de los puntos\n",
    "\n",
    "- *y*, coordenada y de los puntos\n",
    "\n",
    "- *c*, clase de los puntos\n",
    "\n",
    "- *style0*, estilo con el que pintamos los puntos de la clase 0\n",
    "\n",
    "- *style1*, estilo con el que pintamos los puntos de la clase 1\n",
    "\n",
    "- *title*, título para el gráfico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotData(x,y,c,style0,style1,title):\n",
    "    plt.plot(x[c==0],y[c==0],style0)\n",
    "    plt.plot(x[c==1],y[c==1],style1)\n",
    "    plt.grid(True)\n",
    "    plt.axis([x.min()-0.2, x.max()+0.2, y.min()-0.2, y.max()+0.2])\n",
    "    plt.xlabel(\"X\")\n",
    "    plt.ylabel(\"Y\")\n",
    "    plt.title(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizar el conjunto\n",
    "Se entrena un random forest con 3 árboles para visualizar la frontera de decisión cuándo se combinan en el conjunto de clasificadores y cada árbol por separado\n",
    "<div style=\"background-color:#AAEEAA;padding:20px;border:solid;\">Ejecuta el código de con noise=0 y n_estimators=3 y estudia el resultado de los árboles por separado y en conjunto. En concreto analiza:\n",
    "<ul>\n",
    "<li> (1) Las fronteras de decisión de los árboles individuales con respecto a la frontera de los árboles combinados.</li>\n",
    "<li> (2) ¿Por qué son tan diferentes las fronteras de los árboles individuales? Para responder piensa cómo se han creado esos árboles</li>\n",
    "<li> (3) Mira los errores en test de los árboles individuales y del conjunto ¿Cuál es que mejor error obtine? ¿Por qué?</li>\n",
    "</ul>\n",
    "</div>\n",
    "</div>\n",
    "<br/>\n",
    "<div style=\"background-color:#EEEEAA;padding:20px;border:solid;\">Respuestas:\n",
    "<ul>\n",
    "<li> (1) ...</li>\n",
    "<li> (2) ...</li>\n",
    "<li> (3) ...</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#AAEEAA;padding:20px;border:solid;\">Ahora ejecuta las dos celdas siguientes modificando el nivel de ruiso (noise=0.0 y noise=0.3). A continuación prueba con n_estimators igual a 3, 31 y 301 para cada uno de los niveles de ruido y rellena el acierto en test y train en la siguiente tabla:<br/></div>\n",
    "<br>\n",
    "\n",
    "<div style=\"background-color:#EEEEAA;padding:20px;border:solid;\">\n",
    "\n",
    "(4) Respuestas:\n",
    "\n",
    "| Acierto train/test | n_estimators=3 | n_estimators=31 | n_estimators=301 |\n",
    "|--------------------|----------------|-----------------|------------------|\n",
    "| noise=0            |                |                 |                  |\n",
    "| noise=0,3          |                |                 |                  | \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem data:\n",
    "np.random.seed(11)\n",
    "n = 300\n",
    "model = 'sine'\n",
    "ymargin = 0.\n",
    "noise = 0.0                  # <========= Modifica este valor 0 ó 0.3, (antes responde a las cuestiones de arriba)\n",
    "x, y, clase, xbnd, ybnd = createDataSet(n, model, ymargin, noise, True)\n",
    "xtest, ytest, clasetest = createDataSet(n*10, model, ymargin, noise)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construcción del clasificador:\n",
    "np.random.seed(11)\n",
    "clf = RandomForestClassifier(n_estimators=3) # <= Modif este valor 3, 31 y 301(antes responde a las cuestiones de arriba)\n",
    "clf.fit(np.concatenate((x, y), axis = 1), np.ravel(clase))  \n",
    "\n",
    "# Calculo del acierto en los conjuntos de entrenamiento y test:\n",
    "score_train = clf.score(np.concatenate((x, y), axis = 1), np.ravel(clase))\n",
    "print(\"Score train = %f\" % (score_train))\n",
    "score_test = clf.score(np.concatenate((xtest, ytest), axis = 1), np.ravel(clasetest))\n",
    "print(\"Score test = %f\" % (score_test))\n",
    "\n",
    "scores_single_trees_test = [dt.score(np.concatenate((xtest, ytest), axis = 1), np.ravel(clasetest))\n",
    "                            for dt in clf.estimators_[0:3]]\n",
    "\n",
    "print(\"Score test tres primeros árboles = %f,%f,%f\" % tuple(scores_single_trees_test))\n",
    "\n",
    "\n",
    "# Gráficas:\n",
    "plt.figure(figsize=(18,12))\n",
    "plt.subplot(231)\n",
    "plotModel(x,y,clase,clf,\"Training, score = %f\" % (score_train))\n",
    "plt.subplot(234)\n",
    "plotModel(x,y,clase,clf.estimators_[0],\"Arbol 1, test score = %f\" % (scores_single_trees_test[0]))\n",
    "plt.subplot(235)\n",
    "plotModel(x,y,clase,clf.estimators_[1],\"Arbol 1, test score = %f\" % (scores_single_trees_test[1]))\n",
    "plt.subplot(236)\n",
    "plotModel(x,y,clase,clf.estimators_[2],\"Arbol 1, test score = %f\" % (scores_single_trees_test[2]))\n",
    "\n",
    "plt.subplot(232)\n",
    "plotModel(xbnd,ybnd,None,clf,\"Test, score = %f\" % (score_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#AAEEAA;padding:20px;border:solid;\">A continuación se realiza el cálculo el acierto del conjunto con en train y en test con respecto al número de clasificadores combinados. Puedes utilizar la función suministrada individualPredictions, que dado un conjunto de datos y otro de clasificadores devuelve las clasificaciones de cada clasificador base para cada ejemplo\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# individualPredictions: Devuelve la predicción para cada dato por parte de cada clasificador \n",
    "#                        de un conjunto de clasificadores\n",
    "#     Entrada:\n",
    "#         - ens: lista con un conjunto de clasificadores\n",
    "#         - X  : ejemplos a clasificar\n",
    "#     Salida:\n",
    "#         - Matriz de predicciones de número de ejemplo filas y no. clasificadores columnas\n",
    "def individualPredictions(ens, X):\n",
    "    P = np.ones((X.shape[0],len(ens)))\n",
    "    it = 0\n",
    "    for dt in ens:\n",
    "        P[:,it] = dt.predict(X)\n",
    "        it += 1\n",
    "\n",
    "    return P\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "def accuracy(ens, pr, y):\n",
    "    pr = np.cumsum(pr,axis=1)/np.arange(1.,pr.shape[1]+1,1.)\n",
    "    pr[pr>0.5] = 1\n",
    "    pr[pr<=0.5] = 0\n",
    "\n",
    "    iclases_test = np.zeros(np.array([y]).T.shape)\n",
    "    iclases_test[y==ens.classes_[0]] = 0\n",
    "    iclases_test[y==ens.classes_[1]] = 1\n",
    "\n",
    "    Pok = pr==iclases_test\n",
    "    return np.array(Pok.sum(axis=0),dtype=float)/len(y)\n",
    "\n",
    "    \n",
    "# Cargamos datos\n",
    "fP = 'magic04.csv'\n",
    "dfP = pd.read_csv(fP, sep=',')\n",
    "lVarsTarg = dfP.columns\n",
    "\n",
    "#separación training-test\n",
    "X_train, X_test, clases_train, clases_test = train_test_split(dfP.values[:,:-1], dfP.values[:,-1], test_size=0.8, random_state=1)\n",
    "\n",
    "n_trees = 500\n",
    "clf = RandomForestClassifier(n_estimators=n_trees)\n",
    "clf.fit(X_train, clases_train)\n",
    "\n",
    "P = individualPredictions(clf.estimators_, X_train)\n",
    "accu_tr = accuracy(clf,P,clases_train)\n",
    "\n",
    "P = individualPredictions(clf.estimators_, X_test)\n",
    "accu_ts = accuracy(clf,P,clases_test)\n",
    "\n",
    "plt.plot(range(1,n_trees+1),accu_tr,label=\"train\")\n",
    "plt.plot(range(1,n_trees+1),accu_ts,label=\"test\")\n",
    "plt.ylim([0.8,1])\n",
    "_ = plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<div style=\"background-color:#AAEEAA;padding:20px;border:solid;\">Usando la tabla y la gráfica describe cómo evoluciona el error en en entrenemiento y test con respecto al número de árboles que se combinan en el conjunto ¿Se observa sobre ajuste al aumentar el número de clasificadores? Es decir, ¿sube el error en test a partir de algún umbral del número de clasificadores?<br/></div>\n",
    "<br/>\n",
    "<div style=\"background-color:#EEEEAA;padding:20px;border:solid;\">(5) Respuesta: \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting para regresión\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "def plot_par(t,x,y,res,pred,F):\n",
    "    m = np.floor(np.min(y)-1)\n",
    "    M = np.ceil(np.max(y)+1)\n",
    "    plt.subplot(T,2,t*2+1)\n",
    "    plt.stem(x,res,label='residuos')\n",
    "    plt.plot(x,pred,label='h'+str(t),c='y')\n",
    "    plt.ylim((m,M))\n",
    "    plt.legend()\n",
    "    plt.subplot(T,2,t*2+2)\n",
    "    plt.plot(x,y,label='objetivo')\n",
    "    plt.plot(x,F,label='F'+str(t),c='y')\n",
    "    plt.ylim((m,M))\n",
    "    plt.legend()\n",
    "\n",
    "class SquaredErrorLoss:\n",
    "    def F0(_, X, y):\n",
    "        return np.ones(len(X))*np.mean(y)\n",
    "\n",
    "    def residuos(_, y,F):\n",
    "        return y - F\n",
    "\n",
    "    def paso_newton(_, y, res, pred):\n",
    "        return 1\n",
    "    \n",
    "class LogLoss:\n",
    "    def F0(_, X, y):\n",
    "        ymed = np.mean(y)\n",
    "        return np.ones(len(X)) * 0.5 * np.log((1+ymed)/(1-ymed))\n",
    "\n",
    "    def residuos(_, y,F):\n",
    "        return 2.0*y/(1+np.exp(2.0*y*F))\n",
    "\n",
    "    def paso_newton(_, y, res, pred):\n",
    "        return np.sum(res*pred)/np.sum(res*pred*pred*(2.0*y-res))    \n",
    "     \n",
    "def GB(x,y,loss,T):\n",
    "    F = loss.F0(x, y)\n",
    "\n",
    "    #plotting\n",
    "    plt.figure(figsize=(12, T*4))\n",
    "    plot_par(0,x,y,y,F,F)\n",
    "\n",
    "    for t in range(1,T):\n",
    "        res = loss.residuos(y,F)\n",
    "        # Modelo ajustado a residuos\n",
    "        lr = DecisionTreeRegressor(max_depth=1)\n",
    "        lr.fit(x.reshape(-1,1),res)\n",
    "        # Update\n",
    "        pred = lr.predict(x.reshape(-1,1))\n",
    "        paso = loss.paso_newton(y, res, pred)\n",
    "        \n",
    "        F = F + paso*pred\n",
    "        #plotting\n",
    "        plot_par(t,x,y,res,pred,F)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 31\n",
    "\n",
    "# Gradient boosting ejemplo\n",
    "def polinomio(x):\n",
    "    return (x-1)*(x-4)*(x-5) + np.random.randn(len(x))*0.5\n",
    "\n",
    "x = np.linspace(0.5,6,25)\n",
    "y = polinomio(x)\n",
    "\n",
    "loss = SquaredErrorLoss()\n",
    "\n",
    "GB(x,y,loss,T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting para clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 74\n",
    "\n",
    "# Gradient boosting ejemplo\n",
    "def polinomio(x):\n",
    "    return ((x + np.random.randn(len(x))*0.15).astype(int) % 2 ) * 2 - 1\n",
    "\n",
    "x = np.linspace(0.5,6,25)\n",
    "y = polinomio(x)\n",
    "\n",
    "loss = LogLoss()\n",
    "\n",
    "GB(x,y,loss,T)\n",
    "\n",
    "#plt.savefig(\"clasf_gb.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.- Tiempos de entrenamiento y test de los árboles de decisión\n",
    "Vamos a medir tiempos de entrenamiento y clasificación de árboles de decisión y a compararlos con los tiempos de las SVMs. Probaremos a entrenar los modelos con 300 datos y con 600\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.preprocessing as skpp\n",
    "import timeit\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "n_executions = 1\n",
    "\n",
    "# Cargamos datos\n",
    "fP = 'pimaND.csv'\n",
    "dfP = pd.read_csv(fP, sep=',')\n",
    "lVarsTarg = dfP.columns\n",
    "\n",
    "# Dividimos train/test\n",
    "n_train = 300                                      # <================== Modificar 300 o 600\n",
    "perm = np.random.permutation(dfP.shape[0])\n",
    "indices_train = perm[0:n_train]\n",
    "indices_test  = perm[n_train:]\n",
    "\n",
    "    \n",
    "#clf = SVC(C=10.0, kernel='linear', degree=1.0, coef0=1.0, gamma=0.1) # <================== Modificar DT o SVM\n",
    "#clf = tree.DecisionTreeClassifier()\n",
    "clf = RandomForestClassifier(n_estimators=100)  # <================== Modificar 100 o 1000\n",
    "\n",
    "# Tiempo de entrenamiento\n",
    "tic = timeit.default_timer()\n",
    "for ie in range(n_executions):    # Puede ser necesario ejecutarlo varias veces para obtener tiempos más estables\n",
    "    clf.fit(dfP.values[indices_train,:-1],dfP.values[indices_train,-1])\n",
    "toc = timeit.default_timer()\n",
    "\n",
    "print(\"Tiempo de entrenamiento con {} ejemplos: {:.4g} s.\".format(len(indices_train),(toc - tic)/n_executions))\n",
    "\n",
    "n_executions = 10\n",
    "\n",
    "# Tiempo de clasificacion\n",
    "tic = timeit.default_timer()\n",
    "for ie in range(n_executions):   # Puede ser necesario ejecutarlo varias veces para obtener tiempos más estables\n",
    "    _ = clf.predict(dfP.values[indices_test,:-1])\n",
    "toc = timeit.default_timer()\n",
    "\n",
    "factor = 100.\n",
    "print(\"Tiempo de clasificar {:g} ejemplos: {:.4g} s.\".format(factor, factor*(toc - tic)/n_executions/len(indices_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#AAEEAA;padding:20px;border:solid;\">Se debe ejecutar la celda de arriba utilizando conjuntos de clasificadores con 100 y 1000 árboles. Hazlo usando 300 datos de entrenamiento y 600. A continuación se debe rellenar los tiempos en la siguiente tabla comparando con lo obtenido en con árboles y SVM:<br/></div>\n",
    "<br/>\n",
    "<div style=\"background-color:#EEEEAA;padding:20px;border:solid;\">(6) Respuestas:\n",
    "\n",
    "|  Tiempos (s)          | Árbol  | SVM  | RF100 | RF 1000 |\n",
    "|-----------------------|--------|------|-------|---------|\n",
    "| Entrenamiento con 300 | (+)    | (+)  | (++)  | (++)    |\n",
    "| Entrenamiento con 600 | (+)    | (+)  | (++)  | (++)    |\n",
    "| Clasificación con modelo entr. con 300 (10^6 ejemplos) | (+)    | (+)  | (++)  | (++)    |\n",
    "| Clasificación con modelo entr. con 600 (10^6 ejemplos) | (+)    | (+)  | (++)  | (++)    |\n",
    "\n",
    "(+) Recuperar datos de la práctica anterior\n",
    "\n",
    "(++) Rellenar estos datos ejecutando el código de arriba\n",
    "</div>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#AAEEAA;padding:20px;border:solid;\">Usando la tabla comenta los resultados.<br/>\n",
    "\n",
    "<ul>\n",
    "<li>(7) ¿Cómo varían los tiempos de entrenamiento al doblar el número de datos de entrenamiento? ¿Y los tiempos de clasificación?</li>\n",
    "<li>(8): Explica los resultados y comparalos con los de un solo árbol</li>\n",
    "</ul>\n",
    "</div>\n",
    "<br/>\n",
    "<div style=\"background-color:#EEEEAA;padding:20px;border:solid;\">Respuesta:\n",
    "\n",
    "<ul>\n",
    "<li>(7): </li>\n",
    "<li>(8): </li>\n",
    "</ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.- Comparativa\n",
    "Vamos a comparar los resultados de clasificación de algunos conjuntos de clasificadores y árboles de decisión.\n",
    "\n",
    "<div style=\"background-color:#AAEEAA;padding:20px;border:solid;\">Completa el código de abajo para comparar un árbol de decisión y los conjuntos bagging, adaboost y random forest. Se debe obtener el acierto para los conjuntos de datos: pimaND, spamND, magic04 y sonar. Esto se hará usando validación cruzada de 10 hojas.<br/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "# Lista con los ficheros de datos\n",
    "dataset_names = ['sensor.csv', 'pimaND.csv', 'spamND.csv', 'sonar.csv', 'magic04.csv']\n",
    "# Cargo un conjunto de datos\n",
    "idata=1\n",
    "d = pd.read_csv(dataset_names[idata], sep=',')\n",
    "print(dataset_names[idata])\n",
    "\n",
    "# Creamos las particiones en entrenamiento y test para probar los distintos modelos\n",
    "# Es importente que la partición sea igual para todos los modelos de forma que los \n",
    "# errores sean comparables. Eso se puede lograr fijando el random_state\n",
    "indexFolds = KFold(n_splits=10, shuffle=True, random_state=11)\n",
    "\n",
    "# Para conjuntos grades (pe. magic) puede que hacer entrenamiento con el 90% de los datos (como\n",
    "#   sucede con KFold usando n_folds=10) sea inviable. Si tarde damasiado puedes usar la siguiente línea\n",
    "#   para magic y tal vez para spamND\n",
    "#indexFolds = cross_validation.ShuffleSplit(*** RELLENAR AQUI EL TAMAÑO DEL CONJUNTO ***, n_iter=10, test_size=0.8, random_state=0)\n",
    "\n",
    "# Lista con los modelos a probar\n",
    "n_trees = 250\n",
    "modelos = [tree.DecisionTreeClassifier(),\n",
    "          RandomForestClassifier(n_estimators=n_trees),\n",
    "          AdaBoostClassifier(base_estimator=tree.DecisionTreeClassifier(min_samples_leaf=10), \n",
    "                             n_estimators=n_trees),\n",
    "          BaggingClassifier(n_estimators=n_trees)]\n",
    "names= ['DecisionTree', 'RandomForest', 'AdaBoost    ', 'Bagging     ']\n",
    "\n",
    "# Bucle para recorrer cada modelo a probar\n",
    "for n,clf in zip(names, modelos):\n",
    "    errors = []\n",
    "    # Recorremos las particiones\n",
    "    for idxTr, idxTs in indexFolds.split(d):\n",
    "        # Train model\n",
    "        clf.fit(d.values[idxTr,:-1],d.values[idxTr,-1])\n",
    "        # Validate model\n",
    "        score = clf.score(d.values[idxTs,:-1],d.values[idxTs,-1])\n",
    "        errors.append(1.0 - score)\n",
    "\n",
    "    errors = np.array(errors)\n",
    "    print(\"{}: {:0.3g}%%\".format(n,100*errors.mean()) + \" +- {:.3g}\".format(100*errors.std()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<div style=\"background-color:#EEEEAA;padding:20px;border:solid;\"> Resultados:\n",
    "\n",
    "|  Error de test (%) $\\pm$ desv      | Árbol  | RandomForest  | AdaBoost | Bagging |\n",
    "|-----------------------|--------|------|-------|---------|\n",
    "| Pima  | (+)    | (+)  | (+)  | (+)    |\n",
    "| Spam  | (+)    | (+)  | (+)  | (+)    |\n",
    "| Sonar | (+)    | (+)  | (+)  | (+)    |\n",
    "| Magic | (+)    | (+)  | (+)  | (+)    |\n",
    "\n",
    "(+) Rellenar estos datos ejecutando el código implementado. Dar el error y la desviación estándar. Por ejemplo $15.0 \\pm 3.4$\n",
    "</div>\n",
    "<br>\n",
    "<div style=\"background-color:#AAEEAA;padding:20px;border:solid;\">\n",
    "Comenta los resultados:\n",
    "\n",
    "</div>\n",
    "<br/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.- Atributos más importantes\n",
    "Vamos a ver cuáles son los atributos más importantes de los conjuntos de datos analizados arriba. Al entrenar el conjunto se guarda en la variable feature\\_importances\\_ la importancia relativa de cada variable medida en función de cómo de alto aparece en cada árbol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Cargamos datos\n",
    "fP = 'pimaND.csv'\n",
    "dfP = pd.read_csv(fP, sep=',')\n",
    "lVarsTarg = dfP.columns\n",
    "\n",
    "#\n",
    "#separación training-test\n",
    "X_train, X_test, clases_train, clases_test = train_test_split(dfP.values[:,:-1], dfP.values[:,-1], test_size=0.3, random_state=1)\n",
    "\n",
    "# Lista con los modelos a probar\n",
    "n_trees = 301\n",
    "clf= RandomForestClassifier(n_estimators=n_trees)\n",
    "\n",
    "# Entrenamos\n",
    "clf.fit(X_train,clases_train)\n",
    "\n",
    "# Mostramos los atributos más relevantes\n",
    "_ = plt.bar(np.arange(1,dfP.values.shape[1]), clf.feature_importances_)\n",
    "_ = plt.xticks(np.arange(1,dfP.values.shape[1])+0.5, [lab[0:3] for lab in lVarsTarg[:-1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<div style=\"background-color:#EEEEAA;padding:20px;border:solid;\"> Indica las dos variables más importante para cada conjunto de datos:\n",
    "\n",
    "|  Error de test (%) $\\pm$ desv      | Nombre Variable 1 | Nombre Variable 2 |\n",
    "|-----------------------|--------|------|\n",
    "| Pima  | (+)    | (+)  |\n",
    "| Spam  | (+)    | (+)  |\n",
    "| Sonar | (+)    | (+)  |\n",
    "| Magic | (+)    | (+)  |\n",
    "\n",
    "(+) Rellenar estos datos \n",
    "</div>\n",
    "<br>\n",
    "<div style=\"background-color:#AAEEAA;padding:20px;border:solid;\">\n",
    "Comenta los resultados:\n",
    "\n",
    "</div>\n",
    "<br/>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
